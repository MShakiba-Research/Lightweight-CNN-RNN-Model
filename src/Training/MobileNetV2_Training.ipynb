{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa815ee-52a1-405b-bb4a-b91556d27fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import h5py\n",
    "import time\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "# Define image parameters\n",
    "img_width, img_height = 64, 64\n",
    "\n",
    "# Load and preprocess image data\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(folder):\n",
    "        label_folder = os.path.join(folder, label)\n",
    "        for filename in os.listdir(label_folder):\n",
    "            img_path = os.path.join(label_folder, filename)\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            # Convert image to RGB mode\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "            img = img.resize((img_width, img_height), Image.BILINEAR)\n",
    "            img_array = np.array(img)\n",
    "\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "base_folder = os.path.join('../..', 'Augmented_Dataset')\n",
    "\n",
    "# Load images from \"train\" folder\n",
    "train_folder = os.path.join(base_folder, 'train')\n",
    "train_images, train_labels = load_images_from_folder(train_folder)\n",
    "\n",
    "# Load images from \"valid\" folder\n",
    "valid_folder = os.path.join(base_folder, 'valid')\n",
    "valid_images, valid_labels = load_images_from_folder(valid_folder)\n",
    "\n",
    "# Convert string labels to integer class indices\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "valid_labels_encoded = label_encoder.transform(valid_labels)\n",
    "\n",
    "base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(11, activation='softmax')\n",
    "]) \n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define a callback to save the model with the highest validation accuracy\n",
    "checkpoint = ModelCheckpoint('tmp_ResNet50_best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Train the model with the callback\n",
    "model.fit(train_images, train_labels_encoded, epochs=50, batch_size=16, validation_data=(valid_images, valid_labels_encoded), callbacks=[checkpoint])\n",
    "\n",
    "best_model = tf.keras.models.load_model('tmp_MobileNet_best_model.h5')\n",
    "\n",
    "best_model.save('MobileNetV2_best_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7feee-947e-434e-b965-bf8751349173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
